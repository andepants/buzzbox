# Story 6.2: Auto-Processing Cloud Function (Features 1, 4, 5)

## Status
Draft

## Story
**As** Andrew (the creator),
**I want** every fan DM automatically categorized and analyzed,
**so that** I can prioritize my responses based on message type, sentiment, and business opportunity.

## Acceptance Criteria
1. Cloud Function deploys successfully
2. Auto-triggers on new RTDB messages
3. Categorization returns valid category (fan/business/spam/urgent)
4. Sentiment analysis returns valid sentiment (positive/negative/urgent/neutral)
5. Opportunity scoring only runs for business messages
6. All 3 AI features run in parallel (<1s total)
7. Message metadata saved to RTDB
8. iOS displays AI badges correctly
9. Works for all message types
10. Errors don't break message sending (graceful degradation)

## Tasks / Subtasks

- [ ] Verify RTDB message structure (prerequisite)
  - [ ] Check existing iOS message creation code
  - [ ] Verify messages include `receiverId` field in RTDB
  - [ ] Verify messages include `senderId` field
  - [ ] If missing, coordinate with iOS team to add required fields
  - [ ] Document actual RTDB message structure

- [ ] Create auto-processing Cloud Function file (AC: 1)
  - [ ] Create `functions/src/ai-processing.ts`
  - [ ] Import required modules: `firebase-functions/v2/database`, `firebase-admin`, `openai`
  - [ ] Import CREATOR_UID constant from Story 6.0 configuration
  - [ ] Verify constant value: `UoLk9GtxDaaYGlI8Ah6RnCbXXbf2`
  - [ ] Initialize OpenAI client with API key from environment
  - [ ] Define Message interface for type safety

- [ ] Implement RTDB trigger (AC: 2)
  - [ ] Create `processMessageAI` function using `onValueWritten`
  - [ ] Set trigger path: `/messages/{conversationId}/{messageId}`
  - [ ] Configure region: `us-central1`
  - [ ] Handle both new messages and updates (check `change.after.exists()`)

- [ ] Add message filtering logic (AC: 2)
  - [ ] Only process messages sent TO creator (receiverId === CREATOR_UID)
  - [ ] Skip if message already has `aiProcessedAt` (avoid reprocessing)
  - [ ] Skip if message has `aiProcessingFailed: true` (don't retry failures from Story 6.8)
  - [ ] Skip if message was deleted (`!change.after.exists()`)

- [ ] Implement categorization function (AC: 3)
  - [ ] Create `categorizeMessage(text: string)` helper function
  - [ ] Call OpenAI GPT-4o-mini with categorization prompt
  - [ ] System prompt: "Categorize into ONE: fan, business, spam, urgent"
  - [ ] Use temperature: 0.3, max_tokens: 10 for fast responses
  - [ ] Validate response is one of valid categories
  - [ ] Return 'fan' as fallback for invalid responses

- [ ] Implement sentiment analysis function (AC: 4)
  - [ ] Create `analyzeSentiment(text: string)` helper function
  - [ ] Call OpenAI GPT-4o-mini with sentiment prompt
  - [ ] System prompt: "Analyze sentiment. Choose ONE: positive, negative, urgent, neutral"
  - [ ] Use temperature: 0.3, max_tokens: 10 for fast responses
  - [ ] Validate response is one of valid sentiments
  - [ ] Return 'neutral' as fallback for invalid responses

- [ ] Implement opportunity scoring function (AC: 5)
  - [ ] Create `scoreOpportunity(text: string)` helper function
  - [ ] First check if message is categorized as 'business'
  - [ ] Return null if not a business message
  - [ ] For business messages: call OpenAI GPT-4o-mini with scoring prompt
  - [ ] System prompt: "Score 0-100 based on: monetary value, brand fit, legitimacy, urgency"
  - [ ] Use temperature: 0.5, max_tokens: 10
  - [ ] Parse score as integer, validate range 0-100
  - [ ] Return 50 as fallback for invalid scores

- [ ] Implement parallel processing (AC: 6)
  - [ ] Use `Promise.all()` to run all 3 functions in parallel
  - [ ] Destructure results: `[category, sentiment, score]`
  - [ ] Target total execution time: <1 second

- [ ] Update message with AI metadata (AC: 7)
  - [ ] Call `change.after.ref.update()` with metadata object
  - [ ] Include: `aiCategory`, `aiSentiment`, `aiOpportunityScore`
  - [ ] Add `aiProcessedAt: admin.database.ServerValue.TIMESTAMP`
  - [ ] Use Firebase Admin SDK for server-side timestamps

- [ ] Add error handling (AC: 10)
  - [ ] Wrap processing in try/catch block
  - [ ] Log errors with `logger.error()` including context
  - [ ] Return `{ success: false }` on error (don't throw)
  - [ ] Never fail message delivery due to AI processing errors
  - [ ] Log success with `logger.info()` including metadata

- [ ] Add performance monitoring
  - [ ] Log start time before parallel processing begins
  - [ ] Log end time after metadata update completes
  - [ ] Calculate duration in milliseconds
  - [ ] Include in success log: `{ duration, category, sentiment, score }`
  - [ ] Monitor logs to ensure <1s target is met

- [ ] Export function and deploy (AC: 1)
  - [ ] Export `processMessageAI` in `functions/src/index.ts`
  - [ ] Deploy: `firebase deploy --only functions`
  - [ ] Verify deployment succeeds
  - [ ] Check logs for any deployment errors

- [ ] Test with real messages (AC: 8, 9)
  - [ ] Send test fan message from iOS app
  - [ ] Verify AI metadata appears in Firebase Console > RTDB
  - [ ] Send test business message
  - [ ] Verify opportunity score is calculated
  - [ ] Send test spam message
  - [ ] Verify all categories work correctly

## Dev Notes

### Architecture Context

**AI Feature Flow** [Source: architecture/ai-integration-architecture.md#6.1]
- Automatic (Triggered) processing flow:
  1. User sends/receives message → RTDB write
  2. Cloud Function trigger: `onValueWritten` (changed from `onMessageCreated` to support RTDB)
  3. Auto-categorize message (Fan/Business/Spam/Urgent)
  4. Auto-analyze sentiment (Positive/Negative/Urgent/Neutral)
  5. If Business: Auto-score opportunity (0-100)
  6. Update RTDB message document with AI metadata
  7. Real-time listener in iOS app receives update
  8. UI automatically displays category badge and score

**Cloud Functions Specifications** [Source: architecture/ai-integration-architecture.md#6.2]
- Function 1: `onMessageCreated` (this story)
  - Auto-categorize: Fan/Business/Spam/Urgent
  - Auto-analyze sentiment
  - If Business: Score opportunity
  - Update message document
  - Target execution: ~2 seconds (Epic 6 says <1s with GPT-4o-mini)

**AI Model Selection** [Source: docs/prd/epic-6-ai-powered-creator-inbox.md]
- Use GPT-4o-mini for ALL categorization, sentiment, and scoring
- GPT-4o-mini is 15x cheaper than GPT-4 and 3x faster
- Pricing: $0.15/1M input tokens, $0.60/1M output tokens
- Expected latency: <1 second with parallel processing

**Database Strategy** [Source: architecture/technology-stack.md#2.2]
- Real-time Database: Firebase Realtime Database (Chat messages, typing indicators, presence)
- Important: This function triggers on RTDB writes, NOT Firestore
- Path structure: `/messages/{conversationId}/{messageId}`

### Creator Identification

**Creator UID** [Source: docs/prd/epic-6-ai-powered-creator-inbox.md]
- Andrew's Firebase Auth UID: `UoLk9GtxDaaYGlI8Ah6RnCbXXbf2`
- Constant defined in Story 6.0
- Only messages TO the creator (receiverId === CREATOR_UID) are processed
- Messages FROM the creator are not processed by AI

### File Locations

**New File to Create:**
- `functions/src/ai-processing.ts` - Auto-processing Cloud Function implementation

**Files to Modify:**
- `functions/src/index.ts` - Export `processMessageAI` function

### RTDB Message Structure (with AI Metadata)

**Before AI Processing:**
```json
{
  "messages": {
    "conversation_123": {
      "msg_001": {
        "id": "msg_001",
        "text": "Hey, love your content!",
        "senderId": "fan_456",
        "receiverId": "UoLk9GtxDaaYGlI8Ah6RnCbXXbf2",
        "timestamp": 1234567890,
        "status": "sent"
      }
    }
  }
}
```

**After AI Processing:**
```json
{
  "messages": {
    "conversation_123": {
      "msg_001": {
        "id": "msg_001",
        "text": "Hey, love your content!",
        "senderId": "fan_456",
        "receiverId": "UoLk9GtxDaaYGlI8Ah6RnCbXXbf2",
        "timestamp": 1234567890,
        "status": "sent",
        "aiCategory": "fan",
        "aiSentiment": "positive",
        "aiOpportunityScore": null,
        "aiProcessedAt": 1234567891
      }
    }
  }
}
```

### Implementation Details

**Function Signature:**
```typescript
export const processMessageAI = onValueWritten({
  ref: '/messages/{conversationId}/{messageId}',
  region: 'us-central1',
}, async (event) => {
  // Implementation here
});
```

**Parallel Processing Pattern:**
```typescript
const [category, sentiment, score] = await Promise.all([
  categorizeMessage(message.text),
  analyzeSentiment(message.text),
  scoreOpportunity(message.text), // Returns null if not business
]);
```

**GPT-4o-mini Prompts:**

1. **Categorization:**
   - System: "Categorize this message into ONE category: fan, business, spam, or urgent. Respond with only the category word."
   - Temperature: 0.3 (deterministic)
   - Max tokens: 10 (short response)

2. **Sentiment:**
   - System: "Analyze the sentiment of this message. Choose ONE: positive, negative, urgent, or neutral. Respond with only the sentiment word."
   - Temperature: 0.3 (deterministic)
   - Max tokens: 10 (short response)

3. **Opportunity Scoring:**
   - System: "Score this business collaboration opportunity from 0-100 based on: monetary value potential, brand fit for a tech content creator, legitimacy (not spam), urgency. Respond with only a number from 0-100."
   - Temperature: 0.5 (slight variation)
   - Max tokens: 10 (short response)

### Testing

**Testing Approach:**
1. Deploy function to production Firebase
2. Send test messages from iOS app
3. Monitor RTDB in Firebase Console for AI metadata
4. Check function logs: `firebase functions:log`
5. Verify no errors and metadata appears correctly

**Test Cases:**
- Fan message: "I love your videos!" → category: fan, sentiment: positive, score: null
- Business message: "Let's collaborate on a sponsored video worth $5000" → category: business, sentiment: neutral/positive, score: 70-90
- Spam message: "Buy cheap products now!!!" → category: spam, sentiment: neutral, score: null
- Urgent message: "URGENT: Need help with bug in your code ASAP!" → category: urgent, sentiment: urgent/negative, score: null

**Testing Standards** [Source: architecture/testing-strategy.md - assumed]
- Manual testing via deployed function and real messages
- Integration testing with RTDB and iOS app
- Monitor function logs for errors and performance
- No unit tests required for this story (complex to mock OpenAI)

### Important Notes

- This story implements 3 of the 5 required AI features (Features 1, 4, 5)
- Features 2 and 3 are implemented in Stories 6.3 and 6.4
- iOS app does NOT need any code changes in this story
- AI metadata appears automatically via RTDB real-time listeners
- Story 6.7 will add UI components to display the AI badges

### Prerequisites

- Story 6.0 (Environment Configuration) must be complete
- Story 6.1 (Firebase Cloud Functions Setup) must be complete
- OpenAI API key must be configured in Firebase Secrets
- Creator UID constant must be defined

### Cost Estimation

**GPT-4o-mini Pricing:**
- Input: $0.15 per 1M tokens
- Output: $0.60 per 1M tokens

**Per Message Cost (3 parallel calls):**
- Categorization: ~100 input tokens, ~5 output tokens
- Sentiment: ~100 input tokens, ~5 output tokens
- Opportunity: ~100 input tokens, ~5 output tokens (only if business)
- Total: ~300 input tokens, ~15 output tokens
- Cost per message: ~$0.00006 (6 hundredths of a cent)

**Monthly Cost Estimate (100 messages/day):**
- 3,000 messages/month × $0.00006 = $0.18/month
- Extremely cheap with GPT-4o-mini!

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-22 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be populated by dev agent*

### Debug Log References

*To be populated by dev agent*

### Completion Notes

*To be populated by dev agent*

### File List

*To be populated by dev agent*

## QA Results

*This section will be populated by the QA agent after story completion.*
